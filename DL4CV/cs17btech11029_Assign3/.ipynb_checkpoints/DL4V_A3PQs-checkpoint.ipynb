{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou0msMUmgx6m"
   },
   "source": [
    "#### **Welcome to Assignment 3 on Deep Learning for Vision.**\n",
    "\n",
    "\n",
    "#### **Instructions**\n",
    "1. Use Python 3.x to run this notebook\n",
    "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'.\n",
    "you should not change anything else in the code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
    "3. Read documentation of each function carefully.\n",
    "4. All the Best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTuteiZLlJcy"
   },
   "source": [
    "\n",
    "### Question 1: Resnet-18 from scratch\n",
    "\n",
    "In this question, you'll have to code Resnet-18 from scratch (we have provided a lot of starter code), this'll help you get a hold on how to code an architecture with skip connections and blocks of layers.\n",
    "\n",
    "It's suggested you first briefly understand how the Resnet architecture is defined originally before you start with this question. We do take inspiration from the original Pytorch implementation, but if you try peeking into the original source code in the library, it'll confuse you more than helping!\n",
    "\n",
    "Train the model for 15 epochs. Report the train, test loss and accuracies. Also plot epochs vs loss. \n",
    "\n",
    "**Sidenote:** As this assignment is mainly focused on learning things, we train the models only for a small number of epochs and don't focus on hyper-parameter tuning. When you start using deep learning in real-world applications and competitions, hyper-parameter tuning plays a decent role!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GM0uht4kcYVs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import timeit\n",
    "import unittest\n",
    "\n",
    "## Please DONOT remove these lines. \n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhNHc_cjmvoo"
   },
   "outputs": [],
   "source": [
    "# check availability of GPU and set the device accordingly\n",
    "device = \n",
    "\n",
    "# define a set of transforms for preparing the dataset\n",
    "transform_train = transforms.Compose([\n",
    "  # use random crop with image size fo 32 and padding of 8 \n",
    "        # flip the image horizontally (use pytorch random horizontal flip)\n",
    "        # convert the image to a pytorch tensor\n",
    "        # normalise the images with mean and std of the dataset \n",
    "        # mean: (0.4914, 0.4822, 0.4465) std: (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "\n",
    "# define transforms for the test data: Should they be same as the one used for train? \n",
    "transform_test =         # convert the image to a pytorch tensor\n",
    "        # normalise the images with mean and std of the dataset \n",
    "        # mean: (0.4914, 0.4822, 0.4465) std: (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "use_cuda =  # if you have acess to a GPU, enable it to speed the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQciUzi2oF5Q"
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 training, test datasets using `torchvision.datasets.CIFAR10`\n",
    "#### YOUR CODE STARTS HERE ####\n",
    "train_dataset = \n",
    "test_dataset = \n",
    "#### YOUR CODE ENDS HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1Za_R3Yrie2"
   },
   "outputs": [],
   "source": [
    "# create dataloaders for training and test datasets\n",
    "# use a batch size of 32 and set shuffle=True for the training set\n",
    "#### YOUR CODE STARTS HERE ####\n",
    "train_dataloader =\n",
    "test_dataloader = \n",
    "#### YOUR CODE ENDS HERE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCifYwfbT9Ic"
   },
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1):\n",
    "    # define a convolutional layer with a kernel size of 3x3\n",
    "    # use stride, groups values passed to the function along with a padding of 1 and dilatio of 1\n",
    "    # set bias to False\n",
    "    #### YOUR CODE STARTS HERE ####\n",
    "    layer = \n",
    "    #### YOUR CODE ENDS HERE ####\n",
    "    return layer\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    # define a convolutional layer with a kernel size of 1x1\n",
    "    # use stride value passed to the function\n",
    "    # set bias to False\n",
    "    # leave all other parameters to default values\n",
    "    #### YOUR CODE STARTS HERE ####\n",
    "    layer = \n",
    "    #### YOUR CODE ENDS HERE ####\n",
    "    return layer\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # define batch-norm layer to for easy use (you don't have to call it here)\n",
    "        norm_layer = \n",
    "        # define a 3x3 convolution layer with inplanes as in-channels and planes and out_channels, use the passed value of stride\n",
    "        self.conv1 = \n",
    "        # define a batchnorm layer (use the norm_layer defined above)\n",
    "        self.bn1 = \n",
    "        # define a relu layer with inplace set to True\n",
    "        self.relu = \n",
    "        # define a 3x3 convolution layer with inplanes as in-channels and planes and out_channels\n",
    "        self.conv2 = \n",
    "        # define a batchnorm layer (use the norm_layer defined above)\n",
    "        self.bn2 = \n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # make a copy of nput (for using them in skip connections)\n",
    "        identity = \n",
    "\n",
    "        # pass the input through, conv1->bn1->relu->conv2->bn2\n",
    " \n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # add the skip connection\n",
    "        out \n",
    "        # use a relu activation on `out`\n",
    "\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sr00CBjlfqsp"
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "  # first start with make_layer method followed by __init__, forward methods\n",
    "    def __init__(self, block, num_classes=10, groups=1):\n",
    "        super(ResNet18, self).__init__()\n",
    "        \n",
    "        # define batch-norm layer to for easy use (you don't have to call it here)\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        norm_layer = \n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        self._norm_layer = norm_layer\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "\n",
    "        self.groups = groups\n",
    "        self.base_width = 64\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # define a conv layer with number of image channels as in-channels and inplanes ans out-channles,\n",
    "        # use a kernel size of 7, stride of 2, padding of 3 and set bias to False \n",
    "        self.conv1 = \n",
    "        # define a batchnorm layer (use the norm_layer defined above)\n",
    "        self.bn1 = \n",
    "        # define a relu layer with inplace set to True\n",
    "        self.relu = \n",
    "        # define a maxpool layer with kernel size of 3, stride of 2, padding of 1\n",
    "        self.maxpool = \n",
    "        # complete the make layer method below and use it with the block value passed to init\n",
    "        # with 64 planes and 2 blocks\n",
    "        self.layer1 = \n",
    "        # use  make layer method to define a second set of layers with the block value passed to init\n",
    "        # with 128 planes and 2 blocks and a stride value of 2\n",
    "        self.layer2 = \n",
    "        # use  make layer method to define a second set of layers with the block value passed to init\n",
    "        # with 256 planes and 2 blocks and a stride value of 2\n",
    "        self.layer3 = \n",
    "        # use  make layer method to define a second set of layers with the block value passed to init\n",
    "        # with 512 planes and 2 blocks and a stride value of 2\n",
    "        self.layer4 = \n",
    "        # define  adaptive avergae pooling layer with output size (1, 1)\n",
    "        self.avgpool = \n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        #### YOUR CODE STARTS HERE ####        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # initialise the weights with kaiming normal, set mode to fan out and \n",
    "                # non_linearity to the activation function you used above\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                # initialise weights with a value of 1 and bias with a value of 0\n",
    "                \n",
    "         #### YOUR CODE ENDS HERE ####\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            #### YOUR CODE STARTS HERE ####\n",
    "            # append the blocks to layers, leave stride and downsample to default values\n",
    "            \n",
    "            #### YOUR CODE ENDS HERE ####\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #### YOUR CODE STARTS HERE ####\n",
    "        # complete the forward pass\n",
    "        # order of layers: conv1->bn1->relu->maxpool->layer1->layer2->layer3->layer4->avgpool->fc\n",
    "\n",
    "        #### YOUR CODE ENDS HERE ####\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmTBdw1NoNPt"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      #### YOUR CODE STARTS HERE ####\n",
    "        # send the image, target to the device\n",
    "\n",
    "        # flush out the gradients stored in optimizer\n",
    "\n",
    "        # pass the image to the model and assign the output to variable named output\n",
    "\n",
    "        # calculate the loss (use cross entropy in pytorch)\n",
    "\n",
    "        # do a backward pass\n",
    "\n",
    "        # update the weights\n",
    "\n",
    "      #### YOUR CODE ENDS HERE ####\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDSnXB7HpuyN"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "          ### YOUR CODE STARTS HERE ####\n",
    "            # send the image, target to the device\n",
    "\n",
    "            # pass the image to the model and assign the output to variable named output\n",
    "\n",
    "          #### YOUR CODE ENDS HERE ####\n",
    "            test_loss += criterion(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyoPZ87tMzp-"
   },
   "outputs": [],
   "source": [
    "model = ResNet18(BasicBlock, num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "## Define Adam Optimiser with a learning rate of 0.01\n",
    "\n",
    "start = timeit.default_timer()\n",
    "for epoch in range(1, 11):\n",
    "    train(model, device, train_dataloader, criterion, optimizer, epoch)\n",
    "    test(model, device, test_dataloader, criterion)\n",
    "stop = timeit.default_timer()\n",
    "print('Total time taken: {} seconds'.format(int(stop - start)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Plot the saliency map from Pretrained Vgg19 model of the given image using \"simple Gradient\" method. Find out and print the mean and maximum  pixel intensity values of the generated saliency map. Note that the input image has 3 channels. To derive a single class saliency value for each pixel (i, j),  take the maximum magnitude across all colour channels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "#Using VGG-19 pretrained model for image classification\n",
    "\n",
    "model = torchvision.models.vgg19(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Opening the image\n",
    "img = Image.open('input.jpg')\n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess(image, size=224):\n",
    "    transform = T.Compose([\n",
    "        T.Resize((size,size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        T.Lambda(lambda x: x[None]),\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "# preprocess the image\n",
    "X = preprocess(img)\n",
    "\n",
    "### YOUR CODE STARTS HERE ###\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Compute and print the accumulated Attribution over all the input pixels of the given image towards a class (class id-243) output using Integrated Gradient(IG) Method. Assume baseline or reference image to be an image with all zero pixels. Also consider number of steps in IG approximation as 5 and all intermediate step images should follow linear path from baseline image to original image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "# Opening the image\n",
    "img = Image.open('input.jpg') \n",
    "\n",
    "# Preprocess the image\n",
    "def preprocess(image, size=224):\n",
    "    transform = T.Compose([\n",
    "        T.Resize((size,size)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        T.Lambda(lambda x: x[None]),\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "# preprocess the image\n",
    "X = preprocess(img)\n",
    "\n",
    "# we need to find the gradient with respect to the input image, so we need to call requires_grad_ on it\n",
    "X.requires_grad_()\n",
    "\n",
    "class IG():\n",
    "    \"\"\"\n",
    "        Compute attribution of classifier's output from each input pixels using \n",
    "        Integrated Gradient Methood \n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self.model = torchvision.models.vgg19(pretrained=True) \n",
    "        self.gradients = None\n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval()\n",
    "        # Hook the first layer to get the gradient\n",
    "        self.hook_layers()\n",
    "\n",
    "    def hook_layers(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            self.gradients = grad_in[0]\n",
    "\n",
    "        # Register hook to the first layer\n",
    "        first_layer = list(self.model.features._modules.items())[0][1]\n",
    "        first_layer.register_backward_hook(hook_function)\n",
    "\n",
    "    def create_images_on_linear_path(self, input_image, steps):\n",
    "        ''' Create list of all intermediate step images on a linear path\n",
    "            conneting baseline image to original input image\n",
    "        '''\n",
    "        ### YOUR CODE STARTS HERE\n",
    "        \n",
    "        ### YOUR CODE ENDS HERE\n",
    "\n",
    "    def compute_gradients(self, input_image, target_class):\n",
    "        ''' Compute gradient of model's target class output w.r.t to all input pixels'''  \n",
    "\n",
    "        ### YOUR CODE STARTS HERE\n",
    "        \n",
    "        ### YOUR CODE ENDS HERE\n",
    "\n",
    "    def compute_integrated_gradients(self, input_image, target_class, steps):\n",
    "\n",
    "        ''' Main computation of Integrated Gradient method'''\n",
    "        # Generate xbar images\n",
    "        x_list = self.create_images_on_linear_path(input_image, steps)\n",
    "        # Initialize an iamge composed of zeros\n",
    "        integrated_grads = np.zeros(input_image.size())\n",
    "        for x_image in x_list:\n",
    "            # Generate gradients from xbar images\n",
    "            single_integrated_grad = self.compute_gradients(x_image, target_class)\n",
    "            # Add rescaled grads from xbar images\n",
    "            integrated_grads = integrated_grads + single_integrated_grad/steps\n",
    "        # [0] to get rid of the first channel (1,3,224,224)\n",
    "        return integrated_grads[0]\n",
    "\n",
    "### YOUR CODE STARTS HERE\n",
    "\n",
    "### YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "For the given input image, find out and print the channel index and the importance(weight) score of the most important feauture map (out of all the feature maps of final convolution layer of a pretrained ResNet50 model) using Grad-CAM method for the class prediction corresponding to \"highest logit score\". Note that, Grad-CAM produces final heatmap using the weighted combination of the feature map activations, where weights correspond to importance score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "def process_image(img):\n",
    "    means = [0.485, 0.456, 0.406]\n",
    "    stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "    p_img = img.copy()[:, :, ::-1]\n",
    "    for i in range(3):\n",
    "        p_img[:, :, i] = p_img[:, :, i] - means[i]\n",
    "        p_img[:, :, i] = p_img[:, :, i] / stds[i]\n",
    "    p_img = np.ascontiguousarray(np.transpose(p_img, (2, 0, 1)))\n",
    "    p_img = torch.from_numpy(p_img)\n",
    "    p_img.unsqueeze_(0)\n",
    "    input = p_img.requires_grad_(True)\n",
    "    return input\n",
    "\n",
    "class Feat_Extractor():\n",
    "    \"\"\" register gradients get activations from targetted intermediate layers \"\"\"\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "\n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.target_layers:\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x\n",
    "\n",
    "\n",
    "class Netout():\n",
    "    \"\"\" Get network output through forward pass and get intermediate layer representation\n",
    "    and gradient computation for targeted intermediate layer  \"\"\"\n",
    "\n",
    "    def __init__(self, net, feat_module, target_layers):\n",
    "        self.model = net\n",
    "        self.feature_module = feat_module\n",
    "        self.feature_extractor = Feat_Extractor(self.feature_module, target_layers)\n",
    "\n",
    "    def get_gradients(self):\n",
    "        return self.feature_extractor.gradients\n",
    "\n",
    "    def __call__(self, x):\n",
    "        target_activations = []\n",
    "        for name, module in self.model._modules.items():\n",
    "            if module == self.feature_module:\n",
    "                target_activations, x = self.feature_extractor(x)\n",
    "\n",
    "            elif \"avgpool\" in name.lower():\n",
    "                x = module(x)\n",
    "                x = x.view(x.size(0),-1)\n",
    "    \n",
    "            else:\n",
    "                x = module(x)\n",
    "        \n",
    "        return target_activations, x\n",
    "\n",
    "\n",
    "#visualize heatmap on input image\n",
    "def visualize(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    img = np.uint8(255 * cam)\n",
    "    plt.imshow(img)\n",
    "\n",
    "\n",
    "class GradientCam:\n",
    "    def __init__(self, model, feature_module, target_layer_, cuda):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.model.eval()\n",
    "        self.cuda = cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "\n",
    "        self.extractor = Netout(self.model, self.feature_module, target_layer_)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.model(input)\n",
    "\n",
    "    def __call__(self, input, index=None):\n",
    "        \n",
    "        ''' This function should Return weights corresponding to each feature map of last convolution layer.\n",
    "        Note that, linear combination of such weights with last conv layer feature map finally \n",
    "        produce the explanation map'''\n",
    "\n",
    "        ### YOUR CODE STARTS HERE\n",
    "        \n",
    "        \n",
    "        ### YOUR CODE ENDS HERE\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    image = cv2.imread('input.jpg', 1)\n",
    "    image = np.float32(cv2.resize(image, (224, 224))) / 255\n",
    "    input = process_image(image)\n",
    "\n",
    "    net = models.resnet50(pretrained=True)\n",
    "    grad_cam = GradientCam(model=net, feature_module=net.layer4, \\\n",
    "                       target_layer_=[\"2\"], cuda=False)\n",
    "    \n",
    "\n",
    "    target_index = None\n",
    "\n",
    "    ### call to grad_cam method should return the importance vector corresponds to\n",
    "    ### each feature map of last convolution layer of pretrained Resnet50\n",
    "\n",
    "    weights, class_activation_map = grad_cam(input, target_index)\n",
    "\n",
    "    print (\"Most important feature map index: \", np.argmax(weights))\n",
    "    print (\"Its corresponding importance is: \", np.max(weights))\n",
    "\n",
    "    visualize(image, class_activation_map)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL4CV-Assignment-3-Week-5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
